Asistente Visual

Asistente Visual es una aplicaciÃ³n fullâ€‘stack que ayuda a personas con discapacidad visual. Utiliza la cÃ¡mara del mÃ³vil o dispositivo para capturar imÃ¡genes, reconocimiento de voz para recibir preguntas y procesamiento de imÃ¡genes con OCR y detecciÃ³n de objetos (YOLO) en el backend.

ğŸ“‚ Estructura del proyecto

asistente_visual/
â”‚
â”œâ”€ app.py                 # Servidor Flask principal
â”œâ”€ .env                   # Variables de entorno (API keys)
â”œâ”€ requirements.txt       # Dependencias Python
â”œâ”€ yolov8n.pt             # Modelo YOLOv8 ligero
â”œâ”€ yolov8x.pt             # Modelo YOLOv8 mÃ¡s preciso
â”œâ”€ imagenes_recibidas/    # Carpeta donde se guardan las imÃ¡genes capturadas
â”‚
â”œâ”€ templates/
â”‚   â””â”€ index.html         # HTML principal
â”‚
â””â”€ static/
    â”œâ”€ css/
    â”‚   â””â”€ styles.css     # Estilos CSS
    â””â”€ js/
        â””â”€ main.js        # LÃ³gica de cÃ¡mara, voz y fetch al servidor

âš™ï¸ CaracterÃ­sticas

Captura de imagen en tiempo real desde la cÃ¡mara del dispositivo.

Reconocimiento de voz (SpeechRecognition API) en EspaÃ±ol.

EnvÃ­o de imagen y pregunta al backend vÃ­a Flask.

Preprocesamiento de imagen para OCR (binarizaciÃ³n adaptativa).

ExtracciÃ³n de texto con EasyOCR.

DetecciÃ³n de objetos y colores con YOLOv8.

GeneraciÃ³n de respuesta mediante un modelo LLM (Mistral) a travÃ©s de OpenRouter.

SÃ­ntesis de voz de la respuesta (SpeechSynthesis API).

ğŸ“‹ Requisitos

Python 3.8+

Node.js (solo si extiendes frontend con herramientas de bundling)

Una cuenta en OpenRouter y su API key.

ğŸ“¥ InstalaciÃ³n

Clona este repositorio:

git clone https://github.com/albizujon/asistente-visual.git
cd asistente-visual

Crea y activa un entorno virtual:

python -m venv venv
# Windows
venv\Scripts\activate
# macOS / Linux
source venv/bin/activate

Instala dependencias:

pip install -r requirements.txt

Configura las variables de entorno en el archivo .env:

OPENROUTER_OPENROUTER_API_KEY=tu_api_key_aquÃ­
OPENROUTER_ENDPOINT=https://openrouter.ai/api/v1/chat/completions

Descarga los modelos YOLO (yolov8n.pt, yolov8x.pt) y colÃ³calos en la raÃ­z del proyecto.

ğŸš€ Uso

Arranca el servidor:

python app.py

Abre en tu navegador (o mÃ³vil):

http://<IPâ€‘delâ€‘servidor>:5000/

Concede permisos de cÃ¡mara y micrÃ³fono.

Haz click en Hablar y Capturar, formula tu pregunta y espera la respuesta hablada y mostrada en pantalla.

ğŸ§ª Tests

ğŸŒ Despliegue

En producciÃ³n se recomienda Gunicorn + nginx o Docker.

AÃ±adir HTTPS con Let's Encrypt.

ğŸ“– Licencia

MIT Â© 2025 Albizu Jon
